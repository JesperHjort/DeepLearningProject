{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jesper\\appdata\\local\\conda\\conda\\envs\\tensorflowv3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from time import time\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def resize_data(data):\n",
    "    data_upscaled = np.zeros((data.shape[0], 240, 240, 3))\n",
    "    for i, img in enumerate(data):\n",
    "        large_img = cv2.resize(img, dsize=(240, 240), interpolation=cv2.INTER_CUBIC)\n",
    "        data_upscaled[i] = large_img\n",
    "\n",
    "    return data_upscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# read data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# limit the amount of the data\n",
    "Nmax = 200\n",
    "C = 10\n",
    "# train data\n",
    "ind_train = random.sample(list(range(x_train.shape[0])), Nmax)\n",
    "x_train = x_train[ind_train]\n",
    "y_train = y_train[ind_train]\n",
    "\n",
    "# test data\n",
    "ind_test = random.sample(list(range(x_test.shape[0])), Nmax)\n",
    "x_test = x_test[ind_test]\n",
    "y_test = y_test[ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare the data\n",
    "# resize train and  test data\n",
    "x_train_resized = resize_data(x_train)\n",
    "x_test_resized = resize_data(x_test)\n",
    "\n",
    "# make explained variable hot-encoded\n",
    "y_train_hot_encoded = to_categorical(y_train)\n",
    "y_test_hot_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(C, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 7.3739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251f8fb9ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model for the top layers\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(x_train_resized, y_train_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jesper\\appdata\\local\\conda\\conda\\envs\\tensorflowv3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 13s 64ms/step - loss: 8.6185 - acc: 0.1100\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 6.2778 - acc: 0.1300\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 4.6617 - acc: 0.2850\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 4.1951 - acc: 0.3750\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 3.8293 - acc: 0.5050\n"
     ]
    }
   ],
   "source": [
    "# Fit the model for the lower layers\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=\"../../LocalContent/Logs/KerasRetrainInceptionv3_3/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history = model.fit(x_train_resized, y_train_hot_encoded, epochs=5,callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
