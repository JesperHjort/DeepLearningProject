{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import os \n",
    "from time import time\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Basic Guides:\n",
    "# https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n",
    "\n",
    "batch_size = 64\n",
    "Classes = 12\n",
    "N_training = 4000\n",
    "N_verification = 495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_plants(source):\n",
    "    import shutil\n",
    "    \n",
    "    source1 = \"C:/Data/Workspace/GitHub/DeepLearningProject/LocalContent/Datasets/Resized_180/train\"\n",
    "    dest11 =  \"C:/Data/Workspace/GitHub/DeepLearningProject/LocalContent/Datasets/Resized_180/verf\"\n",
    "    folders = os.listdir(source)\n",
    "\n",
    "    x_data = []\n",
    "    \n",
    "    for f in folders:\n",
    "        files = os.listdir(source + '/'+ f)\n",
    "        for i in files:\n",
    "            x = image.load_img(source + '/'+ f + '/' + i)\n",
    "            x = img_to_array(x)\n",
    "            x_data.append(x)\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4255 images belonging to 12 classes.\n",
      "Found 495 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Configure the loading of data\n",
    "# Image Generator\n",
    "# Guied: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=180,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "# Load data for data augmentation\n",
    "x_train = load_data_plants(\"C:/Data/Workspace/GitHub/DeepLearningProject/LocalContent/Datasets/Resized_180/train\")\n",
    "x_verf = load_data_plants(\"C:/Data/Workspace/GitHub/DeepLearningProject/LocalContent/Datasets/Resized_180/verf\")\n",
    "\n",
    "# fit the data augmentation\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# fit the data augmentation\n",
    "val_datagen.fit(x_verf)\n",
    "# Clear to save mem\n",
    "x_train=[]\n",
    "x_verf=[]\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../../LocalContent/Datasets/Resized_180/train',  # this is the target directory\n",
    "       # target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        '../../LocalContent/Datasets/Resized_180/verf',\n",
    "      #  target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(Classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "62/62 [==============================] - 122s 2s/step - loss: 2.7956 - val_loss: 2.2841\n",
      "Epoch 2/2\n",
      "62/62 [==============================] - 115s 2s/step - loss: 1.7159 - val_loss: 2.8115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dcbdb6c710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model for the top layers\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# https://stackoverflow.com/questions/45943675/meaning-of-validation-steps-in-keras-sequential-fit-generator-parameter-list\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.floor(N_training/batch_size),\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=(N_verification/batch_size),\n",
    "        max_queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "62/62 [==============================] - 145s 2s/step - loss: 1.3044 - acc: 0.5633 - val_loss: 1.9936 - val_acc: 0.3192\n",
      "Epoch 2/15\n",
      "62/62 [==============================] - 138s 2s/step - loss: 1.1476 - acc: 0.6457 - val_loss: 1.9385 - val_acc: 0.3549\n",
      "Epoch 3/15\n",
      "62/62 [==============================] - 148s 2s/step - loss: 1.0815 - acc: 0.6752 - val_loss: 1.9143 - val_acc: 0.3594\n",
      "Epoch 4/15\n",
      "62/62 [==============================] - 144s 2s/step - loss: 1.0363 - acc: 0.6888 - val_loss: 1.8904 - val_acc: 0.3638\n",
      "Epoch 5/15\n",
      "62/62 [==============================] - 140s 2s/step - loss: 0.9788 - acc: 0.6966 - val_loss: 1.8811 - val_acc: 0.3638\n",
      "Epoch 6/15\n",
      "62/62 [==============================] - 145s 2s/step - loss: 0.9282 - acc: 0.7272 - val_loss: 1.8280 - val_acc: 0.3705\n",
      "Epoch 7/15\n",
      "62/62 [==============================] - 152s 2s/step - loss: 0.9223 - acc: 0.7188 - val_loss: 1.8273 - val_acc: 0.3705\n",
      "Epoch 8/15\n",
      "62/62 [==============================] - 148s 2s/step - loss: 0.8808 - acc: 0.7297 - val_loss: 1.7808 - val_acc: 0.3772\n",
      "Epoch 9/15\n",
      "62/62 [==============================] - 146s 2s/step - loss: 0.8577 - acc: 0.7491 - val_loss: 1.7748 - val_acc: 0.3862\n",
      "Epoch 10/15\n",
      "62/62 [==============================] - 153s 2s/step - loss: 0.8146 - acc: 0.7563 - val_loss: 1.7157 - val_acc: 0.4107\n",
      "Epoch 11/15\n",
      "62/62 [==============================] - 148s 2s/step - loss: 0.8124 - acc: 0.7518 - val_loss: 1.7147 - val_acc: 0.4196\n",
      "Epoch 12/15\n",
      "62/62 [==============================] - 149s 2s/step - loss: 0.7897 - acc: 0.7602 - val_loss: 1.6654 - val_acc: 0.4397\n",
      "Epoch 13/15\n",
      "62/62 [==============================] - 156s 3s/step - loss: 0.7672 - acc: 0.7594 - val_loss: 1.6465 - val_acc: 0.4375\n",
      "Epoch 14/15\n",
      "62/62 [==============================] - 145s 2s/step - loss: 0.7431 - acc: 0.7645 - val_loss: 1.6209 - val_acc: 0.4353\n",
      "Epoch 15/15\n",
      "62/62 [==============================] - 151s 2s/step - loss: 0.7357 - acc: 0.7766 - val_loss: 1.6104 - val_acc: 0.4442\n"
     ]
    }
   ],
   "source": [
    "# Fit the model for the lower layers\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=\"../../LocalContent/Logs/08_KerasInceptionV3_TestingDirectionLoading/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.floor(N_training/batch_size),\n",
    "        epochs=15,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.floor(N_verification/batch_size),\n",
    "        max_queue_size=1,\n",
    "        callbacks=[tbCallBack])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
